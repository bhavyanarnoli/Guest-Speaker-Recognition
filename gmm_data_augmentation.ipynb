{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from librosa.core.spectrum import _spectrogram\n",
    "import os\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from audiomentations import AddBackgroundNoise, PolarityInversion\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter,\\\n",
    "    AddGaussianSNR,AddShortNoises\n",
    "import random\n",
    "from sklearn import mixture\n",
    "import pickle\n",
    "import pyrubberband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_folders = [\n",
    "    \"Benjamin_Netanyau\",\n",
    "    \"Jens_Stoltenberg\",\n",
    "    \"Julia_Gillard\",\n",
    "    \"Magaret_Tarcher\",\n",
    "    \"Nelson_Mandela\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_save_audio(path,speaker):\n",
    "    files = os.listdir(path)\n",
    "    # files = sorted(files)\n",
    "    # print(sorted(files))\n",
    "    combined_audio = []\n",
    "    temp_sr = 0\n",
    "    for i in range(len(files)):\n",
    "        # print(files[i])\n",
    "        file_path = path + '/' + str(i) + '.wav'\n",
    "        x,sr = librosa.load(file_path)\n",
    "        temp_sr = sr\n",
    "        combined_audio.extend(x)\n",
    "    output_file_path = '../ML_project/combined_audios/' + speaker + '.wav'\n",
    "    sf.write(output_file_path,combined_audio,temp_sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:52<00:00, 10.52s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir('../ML_project/16000_pcm_speeches')):\n",
    "    combine_and_save_audio('../ML_project/16000_pcm_speeches/'+i,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_audio_with_noises(path,speaker):\n",
    "    x,sr = librosa.load(path)\n",
    "    transform = AddBackgroundNoise(\n",
    "        sounds_path=\"../ML_project/_background_noise_\",\n",
    "        min_snr_in_db=3.0,\n",
    "        max_snr_in_db=30.0,\n",
    "        noise_transform=PolarityInversion(),\n",
    "        p=1.0)\n",
    "    augmented_sound = transform(x, sample_rate=sr)\n",
    "    output_file_path = '../ML_project/combindes_audio_with_noises/' + speaker + '.wav'\n",
    "    sf.write(output_file_path,augmented_sound,sr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path):\n",
    "    x,sr = librosa.load(path)\n",
    "    x_pre_emp = librosa.effects.preemphasis(x)\n",
    "    x_mfcc = librosa.feature.mfcc(y=x_pre_emp,sr=sr,n_mfcc=13)\n",
    "    # gfccs  = gfcc(x_pre_emp, num_ceps=13,fs=sr)\n",
    "    # chroma = librosa.feature.chroma_stft(y=x_pre_emp,sr=sr,n_chroma=12)\n",
    "    # print(x_mfcc.shape)\n",
    "    # # print(gfccs.shape)\n",
    "    # print(chroma.shape)\n",
    "    delta_mfcc = librosa.feature.delta(x_mfcc)\n",
    "    double_delta_mfcc = librosa.feature.delta(delta_mfcc)\n",
    "    # delta_gfcc = librosa.feature.delta(gfccs)\n",
    "    # double_delta_gfcc = librosa.feature.delta(delta_gfcc)\n",
    "    # delta_chroma = librosa.feature.delta(chroma)\n",
    "    # double_delta_chroma = librosa.feature.delta(delta_chroma)\n",
    "    combined = np.vstack((x_mfcc,delta_mfcc,double_delta_mfcc))\n",
    "                        #   chroma.T,delta_chroma.T,double_delta_chroma.T)) \n",
    "    # print(combined.shape)'../Kaggle_challenge2/train/bed/00176480_nohash_0.wav'\n",
    "    return combined.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(x,sr=22050):\n",
    "    x_pre_emp = librosa.effects.preemphasis(x)\n",
    "    x_mfcc = librosa.feature.mfcc(y=x_pre_emp,sr=sr,n_mfcc=13)\n",
    "    delta_mfcc = librosa.feature.delta(x_mfcc)\n",
    "    double_delta_mfcc = librosa.feature.delta(delta_mfcc)\n",
    "    combined = np.vstack((x_mfcc,delta_mfcc,double_delta_mfcc))\n",
    "    return combined.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.uniform(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio_extract_features(path,n_steps,rate,flag_value):\n",
    "    x,sr = librosa.load(path)\n",
    "    # x_pre_emp = librosa.effects.preemphasis(x)\n",
    "    \n",
    "    \n",
    "    augmented_pitch_shift = pyrubberband.pyrb.pitch_shift(x,n_steps=n_steps,sr=sr)\n",
    "    augmented_time_stretch = pyrubberband.pyrb.time_stretch(x,rate=rate,sr=sr)\n",
    "\n",
    "    transform_BGN = AddBackgroundNoise(\n",
    "        sounds_path=\"../ML_project/_background_noise_\",\n",
    "        min_snr_in_db=3.0, \n",
    "        max_snr_in_db=30.0,\n",
    "        noise_transform=PolarityInversion(),\n",
    "        p=1.0)\n",
    "    augmented_noise = transform_BGN(x, sample_rate=sr)\n",
    "    add_gaussian_white_noise_transform = AddGaussianSNR(\n",
    "        min_snr_db=5.0,\n",
    "        max_snr_db=40.0,\n",
    "        p=0.2\n",
    "    )\n",
    "    add_short_noises_transform = AddShortNoises(\n",
    "        sounds_path=\"../ML_project/combined_audios\",\n",
    "        min_snr_in_db=3.0,\n",
    "        max_snr_in_db=30.0,\n",
    "        noise_rms=\"relative_to_whole_input\",\n",
    "        min_time_between_sounds=2.0,\n",
    "        max_time_between_sounds=8.0,\n",
    "        noise_transform=PolarityInversion(),\n",
    "        p=0.5\n",
    "    )\n",
    "    add_gaussian_white_noise = add_gaussian_white_noise_transform(x,sr)\n",
    "    add_short_noises = add_short_noises_transform(x,sr)\n",
    "    \n",
    "    features_x = calculate_features(x,sr)\n",
    "    pitch_shift_features = calculate_features(augmented_pitch_shift,sr)\n",
    "    time_stretch_features = calculate_features(augmented_time_stretch,sr)\n",
    "    augmented_noise_feature = calculate_features(augmented_noise,sr)\n",
    "    # print(features_x.shape)\n",
    "    # print(pitch_shift_features.shape)\n",
    "    # print(time_stretch_features.shape)\n",
    "    \n",
    "    # augmented_noise_feature = calculate_features()\n",
    "    if(flag_value>0.5):\n",
    "        white_noise_features = calculate_features(add_gaussian_white_noise,sr)\n",
    "        short_voices_feature = calculate_features(add_short_noises,sr)\n",
    "        return np.vstack((features_x,white_noise_features,pitch_shift_features,\\\n",
    "                         time_stretch_features,augmented_noise_feature,short_voices_feature))\n",
    "    return np.vstack((features_x,pitch_shift_features,time_stretch_features,augmented_noise_feature))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # sf.write('../ML_project/temp.wav',augmented_noise,sr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_test_audio_randomly(path,n_steps,rate):\n",
    "    x,sr = librosa.load(path)\n",
    "    augmented_pitch_shift = pyrubberband.pyrb.pitch_shift(x,n_steps=n_steps,sr=sr)\n",
    "    augmented_time_stretch = pyrubberband.pyrb.time_stretch(x,rate=rate,sr=sr)\n",
    "\n",
    "    transform_BGN = AddBackgroundNoise(\n",
    "        sounds_path=\"../ML_project/_background_noise_\",\n",
    "        min_snr_in_db=3.0,\n",
    "        max_snr_in_db=30.0,\n",
    "        noise_transform=PolarityInversion(),\n",
    "        p=1.0)\n",
    "    augmented_noise = transform_BGN(x, sample_rate=sr)\n",
    "    add_gaussian_white_noise_transform = AddGaussianSNR(\n",
    "        min_snr_db=5.0,\n",
    "        max_snr_db=40.0,\n",
    "        p=0.2\n",
    "    )\n",
    "    add_short_noises_transform = AddShortNoises(\n",
    "        sounds_path=\"../ML_project/combined_audios\",\n",
    "        min_snr_in_db=3.0,\n",
    "        max_snr_in_db=30.0,\n",
    "        noise_rms=\"relative_to_whole_input\",\n",
    "        min_time_between_sounds=2.0,\n",
    "        max_time_between_sounds=8.0,\n",
    "        noise_transform=PolarityInversion(),\n",
    "        p=0.5\n",
    "    )\n",
    "    add_gaussian_white_noise = add_gaussian_white_noise_transform(x,sr)\n",
    "    add_short_noises = add_short_noises_transform(x,sr)\n",
    "    \n",
    "    features_x = calculate_features(x,sr)\n",
    "    pitch_shift_features = calculate_features(augmented_pitch_shift,sr)\n",
    "    time_stretch_features = calculate_features(augmented_time_stretch,sr)\n",
    "    augmented_noise_feature = calculate_features(augmented_noise,sr)\n",
    "    # print(features_x.shape)\n",
    "    # print(pitch_shift_features.shape)\n",
    "    # print(time_stretch_features.shape)\n",
    "    \n",
    "    # augmented_noise_feature = calculate_features()\n",
    "    # if(flag_value>0.5):\n",
    "    white_noise_features = calculate_features(add_gaussian_white_noise,sr)\n",
    "    short_voices_feature = calculate_features(add_short_noises,sr)\n",
    "    #     return np.vstack((features_x,white_noise_features,pitch_shift_features,\\\n",
    "    #                      time_stretch_features,augmented_noise_feature,short_voices_feature))\n",
    "    a = np.random.randint(1,6)\n",
    "    if a==1:\n",
    "        return features_x\n",
    "    elif a==2:\n",
    "        return white_noise_features\n",
    "    elif a==3:\n",
    "        return short_voices_feature\n",
    "    elif a==4:\n",
    "        return pitch_shift_features\n",
    "    elif a==5:\n",
    "        return time_stretch_features\n",
    "    return augmented_noise_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_feature = augment_audio_extract_features('../ML_project/16000_pcm_speeches/Benjamin_Netanyau/18.wav',4,1.2,0.3)\n",
    "# temp_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(os.listdir('../ML_project/combined_audios')):\n",
    "#     combined_audio_with_noises('../ML_project/combined_audios/'+i,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "test_dict = {}\n",
    "for i in os.listdir('../ML_project/16000_pcm_speeches'):\n",
    "    folder_data = os.listdir('../ML_project/16000_pcm_speeches'+'/'+i)\n",
    "    split_80 = int(len(folder_data) * 0.8)\n",
    "    split_20 = len(folder_data) - split_80\n",
    "    list_80 = random.sample(folder_data, split_80)\n",
    "    list_20 = [elem for elem in folder_data if elem not in list_80]\n",
    "    train_dict[i] = list_80\n",
    "    test_dict[i] = list_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [9:23:29<00:00, 6761.92s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for Class,x in tqdm(train_dict.items()):\n",
    "   count = 0\n",
    "   features = np.asarray(())\n",
    "   for file in x:\n",
    "      n_steps = random.uniform(-4,4)\n",
    "      rate = random.uniform(0.7,1.3)\n",
    "      flag_value = random.uniform(0,1)\n",
    "      file_path = '../ML_project/16000_pcm_speeches' + '/' + Class + '/' + file\n",
    "      curr_fea = augment_audio_extract_features(file_path,n_steps=n_steps,rate=rate,\\\n",
    "                                                flag_value=flag_value)\n",
    "      # print(curr_fea.T.shape)\n",
    "      if(count == 0):\n",
    "         features = curr_fea\n",
    "         count+=1\n",
    "      else:\n",
    "         features = np.vstack((features, curr_fea))\n",
    "   gmm1 = mixture.GaussianMixture(n_components = 48, covariance_type='full',n_init = 3,max_iter=10000,init_params='k-means++')\n",
    "   gmm1.fit(features)\n",
    "\n",
    "   picklefile = '../ML_project/Models2/'+Class+'.gmm'\n",
    "   pickle.dump(gmm1, open(picklefile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../ML_project/Models2'\n",
    "models = [pickle.load(open(model_path+'/'+fname,'rb')) for fname in os.listdir(model_path)]\n",
    "speakers   = [fname.split('.')[0] for fname in os.listdir(model_path)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [08:25<00:00, 101.08s/it]\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "for Class,x in tqdm(test_dict.items()):\n",
    "    for file in x:\n",
    "      n_steps = random.uniform(-4,4)\n",
    "      rate = random.uniform(0.7,1.3)\n",
    "      file_path = '../ML_project/16000_pcm_speeches' + '/' + Class + '/' + file\n",
    "      curr_fea = augment_test_audio_randomly(file_path,n_steps,rate)\n",
    "      # print(curr_fea.shape)\n",
    "      y_test.append(Class)\n",
    "      log_likelihood = np.zeros(len(models)) \n",
    "    #   curr_fea = curr_fea.reshape(1,-1)\n",
    "      for i in range(len(models)):\n",
    "          gmm = models[i]         #checking with each model one by one\n",
    "          scores = np.array(gmm.score(curr_fea))\n",
    "          log_likelihood[i] = scores.sum()\n",
    "    \n",
    "      winner = np.argmax(log_likelihood)\n",
    "      y_pred.append(speakers[winner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
